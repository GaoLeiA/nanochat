# NanoChat ä»£ç è§£è¯»æŒ‡å—

> åŸºäº Karpathy çš„ NanoChat é¡¹ç›® - "ç”¨ $100 è®­ç»ƒä¸€ä¸ª LLM"
> çº¦ 8000 è¡Œ PyTorch ä»£ç ï¼Œè¦†ç›– LLM å…¨æ ˆå¼€å‘

---

## ğŸ“š é¡¹ç›®æ¦‚è¿°

NanoChat æ˜¯ä¸€ä¸ªæç®€ã€å¯ hackã€ä¾èµ–å°‘çš„ LLM å…¨æ ˆå®ç°ï¼ŒåŒ…å«ï¼š
- **Tokenization** (åˆ†è¯å™¨è®­ç»ƒ)
- **Pretraining** (é¢„è®­ç»ƒ)  
- **Fine-tuning** (SFTå¾®è°ƒ + å¼ºåŒ–å­¦ä¹ )
- **Evaluation** (è¯„ä¼°)
- **Inference** (æ¨ç†)
- **Chat UI** (Webå¯¹è¯ç•Œé¢)

**æˆæœ¬å¯¹æ¯”**:
- 2019å¹´ GPT-2 è®­ç»ƒæˆæœ¬: ~$43,000
- 2025å¹´ NanoChat GPT-2çº§åˆ«: ~$73-100 (8Ã—H100, çº¦3å°æ—¶)

---

## ğŸ—‚ï¸ ä»£ç ç»“æ„ä¸æ–‡ç« å¯¹ç…§

### é˜¶æ®µä¸€ï¼šåˆ†è¯å™¨ (Tokenization)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/tokenizer.py` | BPEåˆ†è¯å™¨ | RustBPEè®­ç»ƒ + tiktokenæ¨ç† |
| `scripts/tok_train.py` | åˆ†è¯å™¨è®­ç»ƒ | 32Kè¯è¡¨ |
| `scripts/tok_eval.py` | å‹ç¼©ç‡è¯„ä¼° | bytes/token |

```python
# tokenizer.py æ ¸å¿ƒä»£ç 
class RustBPETokenizer:
    def train_from_iterator(cls, text_iterator, vocab_size):
        """è®­ç»ƒBPEåˆ†è¯å™¨ï¼Œvocab_size=32768"""
        
    def render_for_completion(self, conversation):
        """å°†å¯¹è¯æ ¼å¼åŒ–ä¸ºtokensï¼ŒåŒ…å«ç‰¹æ®Štoken"""
```

---

### é˜¶æ®µäºŒï¼šæ¨¡å‹æ¶æ„ (GPT Model)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/gpt.py` | GPT Transformer | ç°ä»£æ”¹è¿›æ¶æ„ |
| `nanochat/flash_attention.py` | æ³¨æ„åŠ›ä¼˜åŒ– | FA3/SDPAè‡ªåŠ¨åˆ‡æ¢ |

**æ¶æ„ç‰¹ç‚¹** (vs åŸç‰ˆGPT-2):
- âœ… RoPEæ—‹è½¬ä½ç½®ç¼–ç  (æ— éœ€å­¦ä¹ ä½ç½®åµŒå…¥)
- âœ… QK Norm (ç¨³å®šè®­ç»ƒ)
- âœ… ReLUÂ² æ¿€æ´»å‡½æ•° (MLP)
- âœ… RMSNorm (æ— å¯å­¦ä¹ å‚æ•°)
- âœ… æ»‘åŠ¨çª—å£æ³¨æ„åŠ› (SSSL pattern)
- âœ… Value Embedding (VE)

```python
# gpt.py æ ¸å¿ƒç»“æ„
@dataclass
class GPTConfig:
    sequence_len: int = 2048    # ä¸Šä¸‹æ–‡é•¿åº¦
    vocab_size: int = 32768     # è¯è¡¨å¤§å°
    n_layer: int = 12           # å±‚æ•° (æ·±åº¦=12å³GPT-1è§„æ¨¡)
    n_head: int = 6             # æ³¨æ„åŠ›å¤´æ•°
    n_kv_head: int = 6          # KVå¤´æ•° (GQA)
    n_embd: int = 768           # éšè—ç»´åº¦
    window_pattern: str = "SSSL" # æ»‘åŠ¨çª—å£æ¨¡å¼

class CausalSelfAttention(nn.Module):
    def forward(self, x, ve, cos_sin, window_size, kv_cache):
        # Flash Attention 3 / SDPA è‡ªåŠ¨åˆ‡æ¢
        y = flash_attn.flash_attn_func(q, k, v, causal=True, window_size=window_size)

class GPT(nn.Module):
    def estimate_flops(self):
        """è®¡ç®—FLOPsç”¨äºMFUç»Ÿè®¡"""
    def num_scaling_params(self):
        """è¿”å›å‚æ•°é‡ç”¨äºscaling lawåˆ†æ"""
```

---

### é˜¶æ®µä¸‰ï¼šæ•°æ®åŠ è½½ (DataLoader)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/dataset.py` | æ•°æ®ä¸‹è½½ | FineWeb-EDU |
| `nanochat/dataloader.py` | åˆ†å¸ƒå¼åŠ è½½ | BOSå¯¹é½+BestFit |

```python
# dataloader.py - BOSå¯¹é½çš„BestFitæ‰“åŒ…
def tokenizing_distributed_data_loader_with_state_bos_bestfit(
    tokenizer, B, T, split, ...
):
    """
    æ¯è¡Œä»¥BOSå¼€å¤´ï¼Œä½¿ç”¨BestFitç®—æ³•æœ€å°åŒ–è£å‰ª
    - 100%åˆ©ç”¨ç‡ (æ— padding)
    - ~35% tokensè¢«è£å‰ª
    """
```

---

### é˜¶æ®µå››ï¼šä¼˜åŒ–å™¨ (Optimizer)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/optim.py` | MuonAdamWä¼˜åŒ–å™¨ | æ··åˆä¼˜åŒ–ç­–ç•¥ |

**ä¼˜åŒ–ç­–ç•¥**:
- **AdamW**: ç”¨äº1Då‚æ•° (embedding, bias, norm)
- **Muon**: ç”¨äº2DçŸ©é˜µå‚æ•° (attention, MLPæƒé‡)

```python
# optim.py æ ¸å¿ƒä»£ç 
class MuonAdamW:
    """
    Muon = MomentUm Orthogonalized by Newton-schulz
    - ä½¿ç”¨Polar ExpressåŠ é€ŸNewton-Schulzè¿­ä»£
    - æ¯”AdamWæ”¶æ•›æ›´å¿«
    """
    
class DistMuonAdamW:
    """åˆ†å¸ƒå¼ç‰ˆæœ¬ - ä¼˜åŒ–AllReduceé€šä¿¡"""
```

---

### é˜¶æ®µäº”ï¼šé¢„è®­ç»ƒ (Pretraining)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `scripts/base_train.py` | é¢„è®­ç»ƒå…¥å£ | torchrunåˆ†å¸ƒå¼ |
| `nanochat/checkpoint_manager.py` | æ£€æŸ¥ç‚¹ç®¡ç† | ä¿å­˜/åŠ è½½ |

```bash
# è¿è¡Œé¢„è®­ç»ƒ (8Ã—H100, ~3å°æ—¶)
torchrun --nproc_per_node=8 -m scripts.base_train -- \
    --depth=24 \
    --run="speedrun" \
    --target-flops=4.1e19
```

```python
# base_train.py è®­ç»ƒå¾ªç¯æ ¸å¿ƒ
for step in range(num_iterations):
    # 1. è·å–æ•°æ®
    x, y = next(train_loader)
    
    # 2. å‰å‘+åå‘ (æ¢¯åº¦ç´¯ç§¯)
    for micro_step in range(grad_accum_steps):
        with autocast_ctx:
            loss = model(x, y)
        loss.backward()
    
    # 3. ä¼˜åŒ–å™¨æ›´æ–°
    optimizer.step()
    
    # 4. è¯„ä¼° (CORE score, BPB)
    if step % eval_every == 0:
        evaluate_core(model, tokenizer)
```

---

### é˜¶æ®µå…­ï¼šSFTå¾®è°ƒ (Supervised Fine-Tuning)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `scripts/chat_sft.py` | SFTè®­ç»ƒ | TaskMixtureæ•°æ® |
| `tasks/*.py` | ä»»åŠ¡æ•°æ®é›† | SmolTalk, MMLUç­‰ |

```python
# chat_sft.py - æ•°æ®æ··åˆ
train_dataset = TaskMixture([
    SmolTalk(split="train"),        # 460Ké€šç”¨å¯¹è¯
    MMLU(subset="auxiliary_train"), # 100Ké€‰æ‹©é¢˜
    GSM8K(split="train"),           # æ•°å­¦é—®é¢˜
    SpellingBee(),                  # æ‹¼å†™ä»»åŠ¡
    CustomJSON("identity.jsonl"),   # è‡ªå®šä¹‰èº«ä»½
])
```

---

### é˜¶æ®µä¸ƒï¼šå¼ºåŒ–å­¦ä¹  (RL)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `scripts/chat_rl.py` | RLè®­ç»ƒ | ç­–ç•¥æ¢¯åº¦ |
| `nanochat/execution.py` | ä»£ç æ‰§è¡Œ | Calculatorå·¥å…· |

---

### é˜¶æ®µå…«ï¼šæ¨ç†æœåŠ¡ (Inference)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/engine.py` | æ¨ç†å¼•æ“ | KVCache + é‡‡æ · |
| `scripts/chat_web.py` | WebæœåŠ¡ | FastAPI + WorkerPool |
| `scripts/chat_cli.py` | CLIå¯¹è¯ | å‘½ä»¤è¡Œäº¤äº’ |
| `nanochat/ui.html` | å‰ç«¯ç•Œé¢ | ChatGPTé£æ ¼UI |

```python
# engine.py æ ¸å¿ƒç»„ä»¶
class KVCache:
    """FA3é£æ ¼KVç¼“å­˜ - (B, T, H, D)æ ¼å¼"""
    
class Engine:
    def generate(self, tokens, num_samples=1, max_tokens=None, 
                 temperature=1.0, top_k=None, seed=42):
        """è‡ªå›å½’ç”Ÿæˆ - Prefill + Decodeå¾ªç¯"""

# chat_web.py - å¤šGPUæ•°æ®å¹¶è¡Œ
class WorkerPool:
    """æ¯ä¸ªGPUä¸€ä¸ªWorkerï¼Œè´Ÿè½½å‡è¡¡åˆ†å‘è¯·æ±‚"""
```

```bash
# å¯åŠ¨WebæœåŠ¡
python -m scripts.chat_web
# è®¿é—® http://localhost:8000
```

---

### é˜¶æ®µä¹ï¼šè¯„ä¼° (Evaluation)

| æ–‡ä»¶ | åŠŸèƒ½ | å…³é”®ç‚¹ |
|------|------|--------|
| `nanochat/core_eval.py` | COREè¯„åˆ† | DCLMåŸºå‡† |
| `nanochat/loss_eval.py` | BPBè¯„ä¼° | bits per byte |
| `scripts/chat_eval.py` | å¯¹è¯è¯„ä¼° | ä»»åŠ¡å‡†ç¡®ç‡ |

**CORE Score**: è¶…è¶ŠGPT-2éœ€è¾¾åˆ° > 0.256525

---

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯äº®ç‚¹

### 1. é«˜æ•ˆè®­ç»ƒä¼˜åŒ–
```
ç¡¬ä»¶: H100 GPU (æ¯”A100å¿«~2x)
è½¯ä»¶: Flash Attention 3, torch.compile
ç®—æ³•: Muonä¼˜åŒ–å™¨, æ»‘åŠ¨çª—å£æ³¨æ„åŠ›
æ•°æ®: FineWeb-EDUé«˜è´¨é‡è¯­æ–™
```

### 2. å…³é”®è¶…å‚æ•°
```python
# depth=24 (GPT-2çº§åˆ«)
n_layer = 24
n_head = 8
n_kv_head = 8  
n_embd = 1024
sequence_len = 2048
vocab_size = 32768
total_batch_size = 524288  # 0.5M tokens/step
```

### 3. è®­ç»ƒæˆæœ¬
| è§„æ¨¡ | æ·±åº¦ | å‚æ•°é‡ | æ—¶é—´ | æˆæœ¬ |
|------|------|--------|------|------|
| GPT-1 | d12 | ~100M | ~5åˆ†é’Ÿ | ~$2 |
| GPT-2 | d24 | ~800M | ~3å°æ—¶ | ~$73 |
| æ›´å¼º | d26+ | ~1B+ | ~42å°æ—¶ | ~$1000 |

---

## ğŸ“ å®Œæ•´æ–‡ä»¶æ¸…å•

```
nanochat/
â”œâ”€â”€ nanochat/                    # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ gpt.py                   # GPTæ¨¡å‹ (GPTConfig, Block, Attention, MLP)
â”‚   â”œâ”€â”€ flash_attention.py       # FA3/SDPAç»Ÿä¸€æ¥å£
â”‚   â”œâ”€â”€ optim.py                 # MuonAdamWä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ tokenizer.py             # BPEåˆ†è¯å™¨
â”‚   â”œâ”€â”€ dataloader.py            # åˆ†å¸ƒå¼æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ dataset.py               # æ•°æ®é›†å·¥å…·
â”‚   â”œâ”€â”€ engine.py                # æ¨ç†å¼•æ“ (KVCache)
â”‚   â”œâ”€â”€ execution.py             # ä»£ç æ‰§è¡Œå·¥å…·
â”‚   â”œâ”€â”€ checkpoint_manager.py    # æ£€æŸ¥ç‚¹ç®¡ç†
â”‚   â”œâ”€â”€ core_eval.py             # COREè¯„ä¼°
â”‚   â”œâ”€â”€ loss_eval.py             # BPBè¯„ä¼°
â”‚   â”œâ”€â”€ report.py                # è®­ç»ƒæŠ¥å‘Š
â”‚   â”œâ”€â”€ common.py                # é€šç”¨å·¥å…·
â”‚   â””â”€â”€ ui.html                  # Webå‰ç«¯
â”‚
â”œâ”€â”€ scripts/                     # å…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ tok_train.py             # åˆ†è¯å™¨è®­ç»ƒ
â”‚   â”œâ”€â”€ tok_eval.py              # åˆ†è¯å™¨è¯„ä¼°
â”‚   â”œâ”€â”€ base_train.py            # é¢„è®­ç»ƒ
â”‚   â”œâ”€â”€ base_eval.py             # åŸºåº§è¯„ä¼°
â”‚   â”œâ”€â”€ chat_sft.py              # SFTå¾®è°ƒ
â”‚   â”œâ”€â”€ chat_rl.py               # å¼ºåŒ–å­¦ä¹ 
â”‚   â”œâ”€â”€ chat_eval.py             # å¯¹è¯è¯„ä¼°
â”‚   â”œâ”€â”€ chat_web.py              # WebæœåŠ¡
â”‚   â””â”€â”€ chat_cli.py              # CLIå¯¹è¯
â”‚
â”œâ”€â”€ tasks/                       # ä»»åŠ¡æ•°æ®é›†
â”‚   â”œâ”€â”€ common.py                # TaskåŸºç±», TaskMixture
â”‚   â”œâ”€â”€ smoltalk.py              # é€šç”¨å¯¹è¯
â”‚   â”œâ”€â”€ mmlu.py                  # å¤šé¢†åŸŸé€‰æ‹©é¢˜
â”‚   â”œâ”€â”€ arc.py                   # ç§‘å­¦é€‰æ‹©é¢˜
â”‚   â”œâ”€â”€ gsm8k.py                 # æ•°å­¦é—®é¢˜
â”‚   â”œâ”€â”€ humaneval.py             # ä»£ç ä»»åŠ¡
â”‚   â”œâ”€â”€ spellingbee.py           # æ‹¼å†™ä»»åŠ¡
â”‚   â””â”€â”€ customjson.py            # è‡ªå®šä¹‰JSONL
â”‚
â””â”€â”€ runs/                        # è®­ç»ƒè„šæœ¬
    â”œâ”€â”€ speedrun.sh              # $100 GPT-2è®­ç»ƒ
    â”œâ”€â”€ scaling_laws.sh          # Scaling lawå®éªŒ
    â”œâ”€â”€ miniseries.sh            # æ¨¡å‹ç³»åˆ—è®­ç»ƒ
    â””â”€â”€ runcpu.sh                # CPU/MPSè¿è¡Œç¤ºä¾‹
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/karpathy/nanochat
cd nanochat

# 2. å®‰è£…ä¾èµ–
pip install -e .

# 3. è®­ç»ƒGPT-2 (8Ã—H100)
bash runs/speedrun.sh

# 4. ä¸æ¨¡å‹å¯¹è¯
python -m scripts.chat_web
```
 
